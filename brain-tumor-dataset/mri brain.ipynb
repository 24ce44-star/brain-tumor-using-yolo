{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66cb338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset split complete!\n",
      "Train images: 325\n",
      "Validation images: 82\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "base_dir = r\"D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\"\n",
    "images_dir = os.path.join(base_dir, \"images\")\n",
    "labels_dir = os.path.join(base_dir, \"labels\")\n",
    "\n",
    "# Create train/val folders\n",
    "for subfolder in [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"]:\n",
    "    os.makedirs(os.path.join(base_dir, subfolder), exist_ok=True)\n",
    "\n",
    "# Collect all JPG images\n",
    "all_images = [f for f in os.listdir(base_dir) if f.endswith(\".jpg\")]\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Split (80% train, 20% val)\n",
    "split_index = int(0.8 * len(all_images))\n",
    "train_images = all_images[:split_index]\n",
    "val_images = all_images[split_index:]\n",
    "\n",
    "def move_files(image_list, set_type):\n",
    "    for img in image_list:\n",
    "        label = img.replace(\".jpg\", \".txt\")\n",
    "        # Move image\n",
    "        shutil.copy(os.path.join(base_dir, img), os.path.join(base_dir, f\"images/{set_type}\", img))\n",
    "        # Move label\n",
    "        if os.path.exists(os.path.join(base_dir, label)):\n",
    "            shutil.copy(os.path.join(base_dir, label), os.path.join(base_dir, f\"labels/{set_type}\", label))\n",
    "\n",
    "move_files(train_images, \"train\")\n",
    "move_files(val_images, \"val\")\n",
    "\n",
    "print(f\"✅ Dataset split complete!\\nTrain images: {len(train_images)}\\nValidation images: {len(val_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e236f8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 4.7MB/s 1.3s.2s<0.1s1.1s2s\n",
      "Ultralytics 8.3.222  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\LENOVO\\runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 1.5MB/s 3.7s.7s<0.0s5ss0.6s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 6.21.8 MB/s, size: 62.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\labels\\train... 325 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 325/325 220.3it/s 1.5s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2.61.1 MB/s, size: 46.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\labels\\val... 82 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 82/82 43.1it/s 1.9s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\LENOVO\\runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\LENOVO\\runs\\detect\\train2\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      2.16G      1.337      3.328       1.54         14        640: 100% ━━━━━━━━━━━━ 21/21 2.7it/s 7.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.9it/s 1.0s0.7s\n",
      "                   all         82         92    0.00362      0.967      0.462      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      2.46G      1.179      1.978       1.34          8        640: 100% ━━━━━━━━━━━━ 21/21 4.4it/s 4.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.8s0.6s\n",
      "                   all         82         92          1     0.0565      0.489      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      2.49G      1.254      1.949      1.408         14        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.9it/s 0.8s0.6s\n",
      "                   all         82         92     0.0887      0.087     0.0476     0.0303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      2.51G      1.287      1.872      1.409          8        640: 100% ━━━━━━━━━━━━ 21/21 4.3it/s 4.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.107     0.0543     0.0284     0.0135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      2.52G      1.305       1.79       1.41         19        640: 100% ━━━━━━━━━━━━ 21/21 4.7it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.442      0.353      0.348      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      2.54G       1.31      1.646      1.437         11        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.8s0.6s\n",
      "                   all         82         92      0.533       0.38      0.369      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      2.55G      1.266      1.511      1.391          6        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.415      0.348      0.286      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      2.57G      1.252      1.428      1.373          9        640: 100% ━━━━━━━━━━━━ 21/21 4.4it/s 4.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.9it/s 0.8s0.6s\n",
      "                   all         82         92       0.66      0.717       0.73      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      2.58G      1.245      1.383      1.406          5        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.3it/s 0.7s0.5s\n",
      "                   all         82         92      0.784      0.631      0.739      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      2.61G      1.195      1.315      1.319          6        640: 100% ━━━━━━━━━━━━ 21/21 4.7it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.788      0.727       0.78      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      2.62G      1.198      1.262      1.343          6        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.905      0.717      0.866      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      2.64G       1.15      1.183      1.306          9        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92       0.73      0.576      0.671      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      2.65G      1.179      1.142      1.296          8        640: 100% ━━━━━━━━━━━━ 21/21 4.7it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.8it/s 0.8s0.6s\n",
      "                   all         82         92      0.899      0.793      0.859      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      2.68G      1.152      1.087      1.275          7        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.3it/s 0.7s0.5s\n",
      "                   all         82         92      0.831      0.685      0.796      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50       2.7G      1.114       1.05      1.282         13        640: 100% ━━━━━━━━━━━━ 21/21 4.7it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.792      0.837      0.863      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      2.71G      1.089      1.077      1.263          9        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.7s0.5s\n",
      "                   all         82         92      0.919      0.783      0.879      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      2.72G      1.098      0.996      1.262         12        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.8s0.5s\n",
      "                   all         82         92       0.89      0.815      0.888      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      2.74G       1.12      1.032      1.256          8        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92       0.89      0.783      0.851      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      2.76G      1.078     0.9781      1.254         11        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.861      0.811      0.874      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      2.78G      1.082     0.9891      1.231          6        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.3it/s 0.7s0.5s\n",
      "                   all         82         92      0.823      0.848      0.875      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      2.79G      1.048     0.8976      1.221         13        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.9it/s 0.8s0.6s\n",
      "                   all         82         92      0.897      0.804      0.904      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      2.81G      1.072     0.9504      1.257          9        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.935      0.788      0.898       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      2.83G      1.046     0.8461      1.215         11        640: 100% ━━━━━━━━━━━━ 21/21 4.7it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.7s0.5s\n",
      "                   all         82         92      0.982      0.761      0.876       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      2.85G      1.044     0.8698      1.195          9        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.826      0.827      0.884      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      2.86G      1.028     0.8532      1.205         13        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.899      0.875      0.923      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      2.88G     0.9652     0.8227       1.15         12        640: 100% ━━━━━━━━━━━━ 21/21 4.3it/s 4.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.8it/s 0.8s0.6s\n",
      "                   all         82         92      0.903      0.859      0.897      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50       2.9G       1.06     0.8691      1.266         12        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.947      0.859      0.898      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      2.92G      1.039     0.8318      1.231         12        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.8s0.5s\n",
      "                   all         82         92       0.94      0.793      0.868        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      2.92G      1.041     0.8456      1.225          8        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.8s0.6s\n",
      "                   all         82         92      0.927      0.859      0.915      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      2.95G      1.006      0.799      1.201          8        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.9it/s 0.8s0.5s\n",
      "                   all         82         92      0.886      0.849      0.915      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      2.97G     0.9713     0.7535      1.169          7        640: 100% ━━━━━━━━━━━━ 21/21 4.4it/s 4.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.919      0.826      0.895      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      2.98G     0.9243     0.7463      1.158          6        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.8it/s 0.8s0.6s\n",
      "                   all         82         92      0.889      0.804      0.906      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      2.99G     0.9909     0.7368      1.195          7        640: 100% ━━━━━━━━━━━━ 21/21 4.3it/s 4.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.972      0.826      0.905      0.681\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      3.02G     0.9638     0.7402      1.181         13        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.9it/s 0.8s0.6s\n",
      "                   all         82         92      0.907      0.849      0.916      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      2.14G     0.9352     0.7012      1.163          6        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.922      0.837      0.907      0.677\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      2.14G     0.9317       0.69      1.142         20        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.941      0.865       0.92      0.674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      2.14G     0.9464     0.7204       1.17          8        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.3it/s 0.7s0.5s\n",
      "                   all         82         92      0.945      0.848      0.929      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      2.14G      0.933     0.7001      1.145         13        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.908      0.853      0.922      0.681\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      2.14G     0.8836     0.6586      1.105         12        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.4it/s 0.7s0.5s\n",
      "                   all         82         92      0.948      0.826      0.926      0.715\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      2.14G     0.8994     0.6504      1.111          6        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.917      0.891      0.932      0.677\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      2.14G     0.8217     0.6148      1.069          5        640: 100% ━━━━━━━━━━━━ 21/21 3.8it/s 5.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.6it/s 0.8s0.6s\n",
      "                   all         82         92       0.93      0.866      0.915      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      2.14G     0.7945     0.5651      1.064          5        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.8it/s 0.8s0.6s\n",
      "                   all         82         92       0.98      0.826      0.916      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      2.14G     0.7771     0.5465      1.042          6        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.962      0.859      0.916       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      2.15G     0.7712     0.5227      1.046          5        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92      0.935       0.87      0.914      0.693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      2.16G     0.7665     0.5132      1.047          5        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2it/s 0.7s0.5s\n",
      "                   all         82         92      0.954      0.859      0.906      0.694\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      2.19G     0.7212     0.4915      1.005          5        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.1it/s 0.7s0.5s\n",
      "                   all         82         92       0.96      0.859      0.913      0.692\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50       2.2G     0.7309     0.5159      1.028          5        640: 100% ━━━━━━━━━━━━ 21/21 4.7it/s 4.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.3it/s 0.7s0.5s\n",
      "                   all         82         92      0.963       0.87      0.914      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      2.22G     0.7237     0.4939      1.011          5        640: 100% ━━━━━━━━━━━━ 21/21 4.5it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.8s0.5s\n",
      "                   all         82         92      0.956      0.859      0.918      0.701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      2.23G     0.7278     0.5065      1.015          5        640: 100% ━━━━━━━━━━━━ 21/21 4.6it/s 4.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.8it/s 0.8s0.6s\n",
      "                   all         82         92      0.954      0.859      0.917      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      2.26G     0.6982     0.4886     0.9869          7        640: 100% ━━━━━━━━━━━━ 21/21 4.4it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.7s0.5s\n",
      "                   all         82         92      0.958      0.859      0.916      0.703\n",
      "\n",
      "50 epochs completed in 0.091 hours.\n",
      "Optimizer stripped from C:\\Users\\LENOVO\\runs\\detect\\train2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\LENOVO\\runs\\detect\\train2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\LENOVO\\runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.222  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.4s0.9s\n",
      "                   all         82         92      0.948      0.826      0.926      0.714\n",
      "Speed: 0.3ms preprocess, 5.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\LENOVO\\runs\\detect\\train2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000013148ECC590>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "             0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,\n",
       "             0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,\n",
       "             0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,\n",
       "             0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,\n",
       "             0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,\n",
       "             0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,\n",
       "             0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,\n",
       "             0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,      0.9863,\n",
       "               0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,\n",
       "               0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,     0.93902,     0.93902,\n",
       "            0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.91765,     0.91765,     0.91765,     0.91765,     0.91765,     0.91765,     0.91765,     0.91765,     0.91765,     0.91765,     0.88889,     0.88889,     0.88889,     0.88889,\n",
       "            0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,\n",
       "            0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,\n",
       "            0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.84848,     0.75221,     0.75221,     0.75221,     0.75221,     0.75221,     0.75221,     0.75221,\n",
       "            0.75221,     0.75221,     0.75221,       0.688,       0.688,       0.688,       0.688,       0.688,       0.688,       0.688,       0.688,       0.688,       0.688,       0.688,     0.58389,     0.58389,     0.58389,     0.58389,     0.58389,     0.58389,     0.58389,     0.58389,     0.58389,\n",
       "            0.58389,     0.58389,     0.22564,     0.22564,     0.22564,     0.22564,     0.22564,     0.22564,     0.22564,     0.22564,     0.22564,     0.22564,     0.22564,     0.15398,     0.15398,     0.15398,     0.15398,     0.15398,     0.15398,     0.15398,     0.15398,     0.15398,     0.15398,\n",
       "            0.15398,     0.13682,     0.13254,     0.12827,     0.12399,     0.11971,     0.11544,     0.11116,     0.10689,     0.10261,    0.098337,    0.094062,    0.089786,    0.085511,    0.081235,     0.07696,    0.072684,    0.068409,    0.064133,    0.059857,    0.055582,    0.051306,    0.047031,\n",
       "           0.042755,     0.03848,    0.034204,    0.029929,    0.025653,    0.021378,    0.017102,    0.012827,   0.0085511,   0.0042755,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.2435,      0.2435,     0.46426,      0.5655,     0.61481,     0.64725,      0.6618,      0.6873,     0.70529,     0.71795,     0.72027,     0.72246,     0.74253,     0.74536,     0.74667,     0.74812,     0.75072,     0.75736,     0.76231,     0.76519,     0.77144,     0.77802,     0.78412,\n",
       "            0.78596,     0.78713,      0.7883,     0.79236,     0.79152,     0.79068,     0.78984,     0.78899,     0.78815,      0.7873,     0.78836,      0.7903,     0.79255,     0.79489,     0.79729,     0.80123,     0.80514,     0.80876,     0.81069,     0.81217,     0.81373,      0.8157,     0.81774,\n",
       "             0.8201,     0.82591,     0.82798,     0.82857,     0.82671,     0.82485,     0.83186,     0.83348,      0.8351,     0.83621,     0.83692,     0.83763,     0.83833,     0.83904,     0.83974,       0.842,     0.84487,     0.84705,     0.84867,     0.84919,     0.84971,     0.85024,     0.85076,\n",
       "            0.85128,     0.85181,     0.85233,     0.85297,      0.8546,     0.85622,     0.86058,     0.86219,     0.86293,     0.86366,      0.8644,     0.86513,     0.86586,     0.86666,     0.86747,     0.86828,     0.86909,      0.8699,     0.87057,      0.8709,     0.87124,     0.87157,     0.87191,\n",
       "            0.87224,     0.87258,     0.87291,     0.87325,     0.87358,     0.87392,     0.87425,     0.87459,     0.87492,     0.87529,     0.87567,     0.87605,     0.87643,     0.87681,     0.87719,     0.87757,     0.87795,     0.87833,     0.87871,     0.87908,     0.87946,     0.87928,     0.87885,\n",
       "            0.87841,     0.87798,     0.87754,     0.87711,     0.87667,     0.87624,      0.8758,     0.87537,     0.87493,     0.87449,     0.87406,     0.87362,     0.87318,     0.87273,     0.87229,     0.87185,      0.8714,     0.87096,     0.87051,     0.87007,     0.86962,     0.86918,     0.86873,\n",
       "            0.86829,     0.86784,     0.87005,     0.87217,     0.87155,     0.87092,      0.8703,     0.86967,     0.86905,     0.86842,     0.86779,     0.86717,     0.86654,     0.86581,     0.86501,     0.86422,     0.86343,     0.86264,     0.86184,     0.86105,     0.86025,     0.86056,     0.86093,\n",
       "            0.86129,     0.86166,     0.86202,     0.86238,     0.86275,     0.86311,     0.86347,     0.86383,      0.8642,     0.86456,     0.86499,     0.86583,     0.86667,     0.86751,     0.86835,     0.86918,     0.86988,     0.87047,     0.87105,     0.87163,     0.87221,     0.87279,     0.87337,\n",
       "            0.87395,     0.87437,     0.87451,     0.87464,     0.87478,     0.87492,     0.87505,     0.87519,     0.87533,     0.87547,      0.8756,     0.87574,     0.87588,     0.87602,     0.87615,     0.87629,     0.87643,     0.87656,      0.8767,     0.87684,     0.87697,     0.87711,     0.87725,\n",
       "            0.87738,     0.87752,     0.87766,     0.87779,     0.87793,     0.87807,      0.8782,     0.87834,     0.87847,     0.87861,     0.87875,     0.87888,     0.87902,     0.87906,      0.8788,     0.87853,     0.87827,     0.87801,     0.87775,     0.87749,     0.87723,     0.87697,     0.87671,\n",
       "            0.87644,     0.87618,     0.87592,     0.87566,      0.8754,     0.87514,     0.87487,     0.87461,     0.87435,     0.87409,     0.87382,     0.87356,      0.8733,     0.87304,     0.87278,     0.87254,     0.87229,     0.87205,      0.8718,     0.87155,     0.87131,     0.87106,     0.87081,\n",
       "            0.87057,     0.87032,     0.87007,     0.86983,     0.86958,     0.86933,     0.86909,     0.86884,     0.86859,     0.86834,      0.8681,     0.86785,      0.8676,     0.86735,     0.86711,     0.86686,     0.86672,     0.86697,     0.86722,     0.86747,     0.86772,     0.86797,     0.86822,\n",
       "            0.86847,     0.86871,     0.86896,     0.86921,     0.86946,     0.86971,     0.86995,      0.8702,     0.87045,      0.8707,     0.87094,     0.87119,     0.87144,     0.87262,     0.87416,      0.8757,     0.87649,     0.87665,      0.8768,     0.87696,     0.87712,     0.87727,     0.87743,\n",
       "            0.87759,     0.87774,      0.8779,     0.87806,     0.87821,     0.87837,     0.87853,     0.87868,     0.87884,       0.879,     0.87915,     0.87931,     0.87946,     0.87962,     0.87978,     0.87993,     0.88009,     0.88024,      0.8804,     0.88055,     0.88071,     0.88086,     0.88102,\n",
       "            0.88118,     0.88133,     0.88045,     0.87937,     0.87828,      0.8772,     0.87611,     0.87502,     0.87533,     0.87567,     0.87601,     0.87634,     0.87668,     0.87702,     0.87735,     0.87769,     0.87803,     0.87836,      0.8787,     0.87903,     0.87937,      0.8797,     0.88005,\n",
       "            0.88052,       0.881,     0.88147,     0.88194,     0.88241,     0.88289,     0.88336,     0.88383,      0.8843,     0.88476,     0.88365,     0.87987,     0.87864,     0.87867,     0.87871,     0.87874,     0.87878,     0.87881,     0.87885,     0.87889,     0.87892,     0.87896,     0.87899,\n",
       "            0.87903,     0.87906,      0.8791,     0.87914,     0.87917,     0.87921,     0.87924,     0.87928,     0.87931,     0.87935,     0.87938,     0.87942,     0.87946,     0.87949,     0.87953,     0.87956,      0.8796,     0.87963,     0.87967,     0.87971,     0.87974,     0.87978,     0.87981,\n",
       "            0.87985,     0.87988,     0.87992,     0.87995,     0.87999,     0.88003,     0.88006,      0.8801,     0.88013,     0.88017,      0.8802,     0.88024,     0.88027,     0.88031,     0.88034,     0.88038,     0.88042,     0.88045,     0.88049,     0.88052,     0.88056,     0.88059,     0.88063,\n",
       "            0.88066,      0.8807,     0.88074,     0.88077,     0.88081,     0.88084,     0.88088,     0.88091,     0.88095,     0.88098,     0.88102,     0.88105,     0.88109,     0.88113,     0.88116,      0.8812,     0.88123,     0.88127,      0.8813,     0.88134,     0.88137,     0.88141,     0.88144,\n",
       "            0.88148,     0.88152,     0.88155,     0.88159,     0.88162,     0.88166,     0.88169,     0.88173,     0.88176,      0.8818,     0.88183,     0.88187,      0.8819,     0.88194,     0.88198,     0.88201,     0.88205,     0.88208,     0.88212,     0.88215,     0.88219,     0.88222,     0.88226,\n",
       "            0.88229,     0.88233,     0.88236,      0.8824,     0.88243,     0.88247,     0.88251,     0.88254,     0.88258,     0.88261,     0.88265,     0.88268,     0.88272,     0.88275,     0.88279,     0.88282,     0.88286,     0.88289,     0.88293,     0.88296,       0.883,     0.88303,     0.88307,\n",
       "            0.88311,     0.88314,     0.88318,     0.88321,     0.88325,     0.88328,     0.88332,     0.88335,     0.88339,     0.88342,     0.88346,     0.88349,     0.88353,     0.88356,      0.8836,     0.88363,     0.88367,      0.8837,     0.88368,     0.88359,      0.8835,     0.88342,     0.88333,\n",
       "            0.88325,     0.88316,     0.88307,     0.88299,      0.8829,     0.88282,     0.88273,     0.88264,     0.88256,     0.88247,     0.88239,      0.8823,     0.88221,     0.88213,     0.88204,     0.88196,     0.88187,     0.88178,      0.8817,     0.88161,     0.88152,     0.88144,     0.88135,\n",
       "            0.88127,     0.88118,     0.88109,     0.88101,     0.88092,     0.88083,     0.88075,     0.88066,     0.88058,     0.88049,      0.8804,     0.88032,     0.88023,     0.88014,     0.88006,     0.87997,     0.87989,      0.8798,     0.87971,     0.87963,     0.87954,     0.87945,     0.87937,\n",
       "            0.87928,     0.87919,     0.87911,     0.87902,     0.87893,     0.87885,     0.87876,     0.87867,     0.87859,      0.8785,     0.87841,     0.87833,     0.87824,     0.87815,     0.87807,     0.87798,     0.87789,     0.87781,     0.87772,     0.87763,     0.87755,     0.87746,     0.87737,\n",
       "            0.87729,      0.8772,      0.8767,     0.87616,     0.87562,     0.87508,     0.87454,       0.874,     0.87346,     0.87291,     0.87237,     0.87183,     0.87128,     0.87074,     0.86977,     0.86863,     0.86749,     0.86635,      0.8652,     0.86406,     0.86362,     0.86329,     0.86296,\n",
       "            0.86263,     0.86231,     0.86198,     0.86165,     0.86132,     0.86099,     0.86066,     0.86033,        0.86,     0.85967,     0.85934,       0.859,     0.85867,     0.85834,     0.85801,     0.85768,     0.85735,      0.8572,     0.85736,     0.85752,     0.85768,     0.85784,     0.85799,\n",
       "            0.85815,     0.85831,     0.85847,     0.85862,     0.85878,     0.85894,      0.8591,     0.85925,     0.85941,     0.85957,     0.85972,     0.85988,     0.86004,      0.8602,     0.86035,     0.86051,     0.86067,     0.86082,     0.86098,     0.86114,     0.86129,     0.86145,      0.8616,\n",
       "            0.86176,     0.86192,     0.86207,     0.86223,     0.86241,      0.8626,     0.86278,     0.86297,     0.86316,     0.86335,     0.86353,     0.86372,     0.86391,      0.8641,     0.86428,     0.86447,     0.86466,     0.86484,     0.86503,     0.86522,      0.8654,     0.86559,     0.86578,\n",
       "            0.86596,     0.86615,     0.86634,     0.86652,     0.86671,     0.86689,     0.86708,     0.86726,     0.86745,     0.86759,     0.86773,     0.86786,       0.868,     0.86813,     0.86827,      0.8684,     0.86854,     0.86868,     0.86881,     0.86895,     0.86908,     0.86922,     0.86935,\n",
       "            0.86949,     0.86962,     0.86976,     0.86989,     0.87003,     0.87016,     0.87029,     0.87043,     0.87056,      0.8707,     0.87083,     0.87097,      0.8711,     0.87124,     0.87137,      0.8715,     0.87164,     0.87177,     0.87191,     0.87204,     0.87217,     0.87231,     0.87244,\n",
       "            0.87258,     0.87271,     0.87247,     0.87217,     0.87187,     0.87157,     0.87127,     0.87097,     0.87068,     0.87038,     0.87008,     0.86978,     0.86948,     0.86918,     0.86888,     0.86858,     0.86828,     0.86798,     0.86768,     0.86738,     0.86708,     0.86677,     0.86647,\n",
       "            0.86617,     0.86587,     0.86551,     0.86515,     0.86478,     0.86442,     0.86405,     0.86369,     0.86332,     0.86296,     0.86259,     0.86223,     0.86186,     0.86149,     0.86113,     0.86076,     0.86039,     0.86003,     0.85966,     0.85929,     0.85892,     0.85625,     0.85336,\n",
       "            0.85169,     0.85136,     0.85103,      0.8507,     0.85037,     0.85004,     0.84971,     0.84938,     0.84904,     0.84871,     0.84838,     0.84805,     0.84772,     0.84738,     0.84705,     0.84672,     0.84638,     0.84605,     0.84572,     0.84538,     0.84505,      0.8447,     0.84384,\n",
       "            0.84297,      0.8421,     0.84123,     0.84036,     0.83949,     0.83861,     0.83774,     0.83719,     0.83676,     0.83634,     0.83591,     0.83548,     0.83506,     0.83463,      0.8342,     0.83377,     0.83335,     0.83292,     0.83249,     0.83206,     0.83163,      0.8312,     0.83077,\n",
       "            0.83034,     0.82982,     0.82926,      0.8287,     0.82814,     0.82758,     0.82702,     0.82646,      0.8259,     0.82533,     0.82477,     0.82421,     0.82364,     0.82308,     0.82222,     0.82104,     0.81986,     0.81868,     0.81749,     0.81631,     0.81518,     0.81444,     0.81371,\n",
       "            0.81297,     0.81223,     0.81149,     0.81074,        0.81,     0.80926,     0.80851,     0.80777,     0.80669,     0.80556,     0.80444,     0.80331,     0.80218,     0.80105,     0.79988,     0.79811,     0.79634,     0.79456,     0.79278,     0.78856,     0.78314,     0.77768,     0.77216,\n",
       "              0.767,      0.7628,     0.75885,     0.75545,     0.75202,     0.74858,     0.74512,     0.74801,     0.74404,      0.7397,     0.73822,     0.73674,     0.73526,     0.73377,     0.73228,     0.72953,     0.72187,     0.72005,     0.71822,     0.71639,     0.71455,     0.71038,     0.70105,\n",
       "            0.69274,     0.68636,     0.67465,     0.67072,     0.66677,      0.6371,     0.62664,     0.61644,     0.61431,     0.61216,     0.61002,     0.60786,     0.60485,     0.59758,     0.57935,     0.57255,     0.56799,     0.56341,     0.54805,     0.54412,     0.54018,     0.52092,     0.51106,\n",
       "             0.4931,     0.47968,     0.47515,     0.47082,     0.46606,     0.45331,     0.44662,     0.43906,     0.42656,     0.42102,     0.41544,     0.40385,     0.39652,     0.39174,     0.38692,     0.36573,     0.35826,     0.35348,     0.34915,      0.3448,     0.33563,     0.32439,     0.31811,\n",
       "            0.31181,      0.3065,     0.30116,      0.2932,     0.24703,     0.24213,     0.23719,     0.23223,     0.22253,     0.21187,     0.20471,      0.1975,     0.19121,     0.18512,     0.17898,     0.17358,     0.16825,      0.1629,     0.15125,     0.12098,     0.11795,     0.11491,     0.11186,\n",
       "             0.1088,     0.10573,     0.10283,       0.101,    0.099176,    0.097344,    0.095509,    0.093671,    0.091828,    0.089983,    0.088133,     0.08628,    0.084424,    0.066255,    0.043616,    0.040992,    0.039346,    0.037697,    0.036046,    0.034391,    0.032734,    0.031075,    0.029412,\n",
       "           0.027746,    0.026078,    0.024407,    0.022733,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.13928,     0.13928,     0.30765,     0.40336,     0.45546,       0.492,     0.50901,     0.53982,     0.56235,     0.57862,     0.58298,     0.58874,     0.61587,     0.61977,     0.62158,      0.6236,     0.62722,     0.63655,     0.64357,     0.64769,     0.65669,     0.66628,     0.67529,\n",
       "            0.67801,     0.67976,      0.6815,     0.68788,      0.6875,     0.68712,     0.68674,     0.68636,     0.68598,      0.6856,      0.6875,     0.69045,     0.69389,     0.69749,      0.7012,      0.7073,     0.71343,     0.71913,     0.72219,     0.72454,     0.72702,     0.73018,     0.73346,\n",
       "            0.73726,     0.74671,     0.75009,     0.75194,     0.75123,     0.75051,     0.76394,     0.76668,     0.76941,     0.77131,     0.77251,     0.77372,     0.77493,     0.77613,     0.77734,     0.78122,     0.78616,     0.78996,     0.79277,     0.79368,      0.7946,     0.79552,     0.79643,\n",
       "            0.79735,     0.79827,     0.79919,     0.80032,     0.80319,     0.80605,     0.81382,      0.8167,     0.81802,     0.81935,     0.82067,       0.822,     0.82332,     0.82477,     0.82624,     0.82771,     0.82918,     0.83065,     0.83186,     0.83248,     0.83309,     0.83371,     0.83432,\n",
       "            0.83494,     0.83555,     0.83617,     0.83678,     0.83739,     0.83801,     0.83862,     0.83924,     0.83985,     0.84053,     0.84124,     0.84194,     0.84264,     0.84334,     0.84405,     0.84475,     0.84545,     0.84616,     0.84686,     0.84756,     0.84826,     0.84841,     0.84829,\n",
       "            0.84818,     0.84806,     0.84795,     0.84784,     0.84772,     0.84761,     0.84749,     0.84738,     0.84726,     0.84715,     0.84704,     0.84692,      0.8468,     0.84669,     0.84657,     0.84645,     0.84633,     0.84622,      0.8461,     0.84598,     0.84586,     0.84574,     0.84563,\n",
       "            0.84551,     0.84539,     0.84978,     0.85412,     0.85396,      0.8538,     0.85365,     0.85349,     0.85333,     0.85317,     0.85301,     0.85285,     0.85269,      0.8525,      0.8523,     0.85209,     0.85189,     0.85169,     0.85148,     0.85128,     0.85107,     0.85175,     0.85246,\n",
       "            0.85318,     0.85389,     0.85461,     0.85532,     0.85603,     0.85675,     0.85746,     0.85818,     0.85889,     0.85961,     0.86047,     0.86213,      0.8638,     0.86547,     0.86713,      0.8688,      0.8702,     0.87137,     0.87254,     0.87371,     0.87488,     0.87605,     0.87721,\n",
       "            0.87838,     0.87922,      0.8795,     0.87978,     0.88006,     0.88034,     0.88061,     0.88089,     0.88117,     0.88145,     0.88173,     0.88201,     0.88228,     0.88256,     0.88284,     0.88312,      0.8834,     0.88367,     0.88395,     0.88423,     0.88451,     0.88479,     0.88506,\n",
       "            0.88534,     0.88562,      0.8859,     0.88618,     0.88646,     0.88673,     0.88701,     0.88729,     0.88757,     0.88785,     0.88812,      0.8884,     0.88868,     0.88888,     0.88882,     0.88877,     0.88872,     0.88866,     0.88861,     0.88856,     0.88851,     0.88845,      0.8884,\n",
       "            0.88835,      0.8883,     0.88824,     0.88819,     0.88814,     0.88808,     0.88803,     0.88798,     0.88793,     0.88787,     0.88782,     0.88777,     0.88771,     0.88766,     0.88761,     0.88756,     0.88751,     0.88746,     0.88741,     0.88736,     0.88731,     0.88726,     0.88721,\n",
       "            0.88716,     0.88711,     0.88706,     0.88701,     0.88696,     0.88691,     0.88686,     0.88681,     0.88675,      0.8867,     0.88665,      0.8866,     0.88655,      0.8865,     0.88645,      0.8864,     0.88648,       0.887,     0.88753,     0.88805,     0.88857,     0.88909,     0.88961,\n",
       "            0.89014,     0.89066,     0.89118,      0.8917,     0.89223,     0.89275,     0.89327,     0.89379,     0.89431,     0.89484,     0.89536,     0.89588,      0.8964,      0.8989,     0.90219,     0.90548,     0.90716,      0.9075,     0.90783,     0.90817,     0.90851,     0.90884,     0.90918,\n",
       "            0.90952,     0.90985,     0.91019,     0.91053,     0.91086,      0.9112,     0.91153,     0.91187,     0.91221,     0.91254,     0.91288,     0.91322,     0.91355,     0.91389,     0.91423,     0.91456,      0.9149,     0.91524,     0.91557,     0.91591,     0.91625,     0.91658,     0.91692,\n",
       "            0.91726,     0.91759,     0.91751,     0.91734,     0.91717,       0.917,     0.91684,     0.91667,      0.9174,     0.91814,     0.91888,     0.91962,     0.92037,     0.92111,     0.92185,     0.92259,     0.92334,     0.92408,     0.92482,     0.92556,      0.9263,     0.92705,     0.92782,\n",
       "            0.92888,     0.92993,     0.93099,     0.93204,     0.93309,     0.93415,      0.9352,     0.93626,     0.93731,     0.93836,     0.93886,     0.93842,     0.93833,     0.93841,     0.93849,     0.93857,     0.93865,     0.93873,     0.93881,      0.9389,     0.93898,     0.93906,     0.93914,\n",
       "            0.93922,      0.9393,     0.93938,     0.93947,     0.93955,     0.93963,     0.93971,     0.93979,     0.93987,     0.93995,     0.94003,     0.94012,      0.9402,     0.94028,     0.94036,     0.94044,     0.94052,      0.9406,     0.94069,     0.94077,     0.94085,     0.94093,     0.94101,\n",
       "            0.94109,     0.94117,     0.94126,     0.94134,     0.94142,      0.9415,     0.94158,     0.94166,     0.94174,     0.94182,     0.94191,     0.94199,     0.94207,     0.94215,     0.94223,     0.94231,     0.94239,     0.94248,     0.94256,     0.94264,     0.94272,      0.9428,     0.94288,\n",
       "            0.94296,     0.94305,     0.94313,     0.94321,     0.94329,     0.94337,     0.94345,     0.94353,     0.94361,      0.9437,     0.94378,     0.94386,     0.94394,     0.94402,      0.9441,     0.94418,     0.94427,     0.94435,     0.94443,     0.94451,     0.94459,     0.94467,     0.94475,\n",
       "            0.94484,     0.94492,       0.945,     0.94508,     0.94516,     0.94524,     0.94532,      0.9454,     0.94549,     0.94557,     0.94565,     0.94573,     0.94581,     0.94589,     0.94597,     0.94606,     0.94614,     0.94622,      0.9463,     0.94638,     0.94646,     0.94654,     0.94663,\n",
       "            0.94671,     0.94679,     0.94687,     0.94695,     0.94703,     0.94711,     0.94719,     0.94728,     0.94736,     0.94744,     0.94752,      0.9476,     0.94768,     0.94776,     0.94785,     0.94793,     0.94801,     0.94809,     0.94817,     0.94825,     0.94833,     0.94842,      0.9485,\n",
       "            0.94858,     0.94866,     0.94874,     0.94882,      0.9489,     0.94898,     0.94907,     0.94915,     0.94923,     0.94931,     0.94939,     0.94947,     0.94955,     0.94964,     0.94972,      0.9498,     0.94988,     0.94996,        0.95,     0.94999,     0.94998,     0.94997,     0.94996,\n",
       "            0.94995,     0.94995,     0.94994,     0.94993,     0.94992,     0.94991,      0.9499,      0.9499,     0.94989,     0.94988,     0.94987,     0.94986,     0.94985,     0.94984,     0.94984,     0.94983,     0.94982,     0.94981,      0.9498,     0.94979,     0.94979,     0.94978,     0.94977,\n",
       "            0.94976,     0.94975,     0.94974,     0.94974,     0.94973,     0.94972,     0.94971,      0.9497,     0.94969,     0.94969,     0.94968,     0.94967,     0.94966,     0.94965,     0.94964,     0.94964,     0.94963,     0.94962,     0.94961,      0.9496,     0.94959,     0.94959,     0.94958,\n",
       "            0.94957,     0.94956,     0.94955,     0.94954,     0.94954,     0.94953,     0.94952,     0.94951,      0.9495,     0.94949,     0.94948,     0.94948,     0.94947,     0.94946,     0.94945,     0.94944,     0.94943,     0.94943,     0.94942,     0.94941,      0.9494,     0.94939,     0.94938,\n",
       "            0.94938,     0.94937,     0.94932,     0.94927,     0.94921,     0.94916,     0.94911,     0.94905,       0.949,     0.94895,     0.94889,     0.94884,     0.94879,     0.94873,     0.94864,     0.94852,     0.94841,     0.94829,     0.94818,     0.94807,     0.94802,     0.94799,     0.94796,\n",
       "            0.94792,     0.94789,     0.94786,     0.94782,     0.94779,     0.94776,     0.94772,     0.94769,     0.94766,     0.94762,     0.94759,     0.94756,     0.94752,     0.94749,     0.94746,     0.94742,     0.94739,     0.94752,      0.9479,     0.94829,     0.94868,     0.94906,     0.94945,\n",
       "            0.94983,     0.95022,     0.95061,     0.95099,     0.95138,     0.95177,     0.95215,     0.95254,     0.95293,     0.95331,      0.9537,     0.95409,     0.95447,     0.95486,     0.95525,     0.95563,     0.95602,     0.95641,     0.95679,     0.95718,     0.95756,     0.95795,     0.95834,\n",
       "            0.95872,     0.95911,      0.9595,     0.95988,     0.96033,     0.96079,     0.96126,     0.96173,     0.96219,     0.96266,     0.96313,     0.96359,     0.96406,     0.96453,     0.96499,     0.96546,     0.96593,     0.96639,     0.96686,     0.96732,     0.96779,     0.96826,     0.96872,\n",
       "            0.96919,     0.96966,     0.97012,     0.97059,     0.97106,     0.97152,     0.97199,     0.97246,     0.97292,     0.97328,     0.97362,     0.97396,      0.9743,     0.97464,     0.97499,     0.97533,     0.97567,     0.97601,     0.97635,     0.97669,     0.97704,     0.97738,     0.97772,\n",
       "            0.97806,      0.9784,     0.97874,     0.97908,     0.97943,     0.97977,     0.98011,     0.98045,     0.98079,     0.98113,     0.98148,     0.98182,     0.98216,      0.9825,     0.98284,     0.98318,     0.98352,     0.98387,     0.98421,     0.98455,     0.98489,     0.98523,     0.98557,\n",
       "            0.98592,     0.98626,     0.98629,     0.98629,     0.98628,     0.98627,     0.98626,     0.98625,     0.98624,     0.98624,     0.98623,     0.98622,     0.98621,      0.9862,     0.98619,     0.98619,     0.98618,     0.98617,     0.98616,     0.98615,     0.98614,     0.98614,     0.98613,\n",
       "            0.98612,     0.98611,      0.9861,     0.98609,     0.98608,     0.98607,     0.98606,     0.98605,     0.98604,     0.98603,     0.98602,     0.98601,       0.986,     0.98599,     0.98598,     0.98597,     0.98596,     0.98595,     0.98594,     0.98593,     0.98592,     0.98584,     0.98576,\n",
       "            0.98571,      0.9857,     0.98569,     0.98568,     0.98567,     0.98566,     0.98565,     0.98564,     0.98563,     0.98562,     0.98561,      0.9856,     0.98559,     0.98558,     0.98557,     0.98556,     0.98556,     0.98555,     0.98554,     0.98553,     0.98552,     0.98551,     0.98548,\n",
       "            0.98546,     0.98543,      0.9854,     0.98538,     0.98535,     0.98533,      0.9853,     0.98528,     0.98527,     0.98526,     0.98525,     0.98523,     0.98522,     0.98521,     0.98519,     0.98518,     0.98517,     0.98516,     0.98514,     0.98513,     0.98512,      0.9851,     0.98509,\n",
       "            0.98508,     0.98506,     0.98505,     0.98503,     0.98501,     0.98499,     0.98498,     0.98496,     0.98494,     0.98493,     0.98491,     0.98489,     0.98487,     0.98486,     0.98483,     0.98479,     0.98476,     0.98472,     0.98468,     0.98465,     0.98461,     0.98459,     0.98457,\n",
       "            0.98454,     0.98452,     0.98449,     0.98447,     0.98445,     0.98442,      0.9844,     0.98438,     0.98434,     0.98431,     0.98427,     0.98423,      0.9842,     0.98416,     0.98412,     0.98406,     0.98401,     0.98395,     0.98389,     0.98375,     0.98357,     0.98338,     0.98319,\n",
       "            0.98301,     0.98286,     0.98272,     0.98259,     0.98247,     0.98234,     0.98221,     0.99898,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.96739,     0.96739,     0.94565,     0.94565,     0.94565,     0.94565,     0.94565,     0.94565,     0.94565,     0.94565,     0.94213,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,\n",
       "            0.93478,     0.93478,     0.93478,     0.93427,     0.93263,     0.93099,     0.92935,     0.92771,     0.92607,     0.92443,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,     0.92391,\n",
       "            0.92391,     0.92391,     0.92391,      0.9226,     0.91907,     0.91554,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,\n",
       "            0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,\n",
       "            0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91304,     0.91249,     0.91169,\n",
       "            0.91089,     0.91008,     0.90928,     0.90848,     0.90767,     0.90687,     0.90607,     0.90527,     0.90446,     0.90366,     0.90286,     0.90205,     0.90124,     0.90043,     0.89962,     0.89881,       0.898,     0.89719,     0.89638,     0.89557,     0.89476,     0.89395,     0.89314,\n",
       "            0.89233,     0.89152,      0.8913,       0.891,     0.88987,     0.88874,     0.88761,     0.88648,     0.88536,     0.88423,      0.8831,     0.88197,     0.88084,     0.87953,     0.87812,      0.8767,     0.87529,     0.87387,     0.87246,     0.87104,     0.86963,     0.86957,     0.86957,\n",
       "            0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,\n",
       "            0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,\n",
       "            0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86945,     0.86899,     0.86853,     0.86807,     0.86761,     0.86715,     0.86669,     0.86623,     0.86578,     0.86532,\n",
       "            0.86486,      0.8644,     0.86394,     0.86348,     0.86302,     0.86256,      0.8621,     0.86164,     0.86118,     0.86072,     0.86026,      0.8598,     0.85934,     0.85888,     0.85844,     0.85801,     0.85759,     0.85716,     0.85673,      0.8563,     0.85587,     0.85544,     0.85501,\n",
       "            0.85459,     0.85416,     0.85373,      0.8533,     0.85287,     0.85244,     0.85201,     0.85159,     0.85116,     0.85073,      0.8503,     0.84987,     0.84944,     0.84901,     0.84859,     0.84816,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,\n",
       "            0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,\n",
       "            0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,     0.84783,\n",
       "            0.84783,     0.84783,     0.84627,     0.84441,     0.84256,      0.8407,     0.83884,     0.83699,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,\n",
       "            0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83696,     0.83457,     0.82821,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,\n",
       "            0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,\n",
       "            0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,\n",
       "            0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,\n",
       "            0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,\n",
       "            0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,\n",
       "            0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82601,     0.82587,     0.82572,     0.82558,     0.82544,\n",
       "            0.82529,     0.82515,     0.82501,     0.82486,     0.82472,     0.82457,     0.82443,     0.82429,     0.82414,       0.824,     0.82386,     0.82371,     0.82357,     0.82342,     0.82328,     0.82314,     0.82299,     0.82285,     0.82271,     0.82256,     0.82242,     0.82227,     0.82213,\n",
       "            0.82199,     0.82184,      0.8217,     0.82155,     0.82141,     0.82127,     0.82112,     0.82098,     0.82084,     0.82069,     0.82055,      0.8204,     0.82026,     0.82012,     0.81997,     0.81983,     0.81969,     0.81954,      0.8194,     0.81925,     0.81911,     0.81897,     0.81882,\n",
       "            0.81868,     0.81854,     0.81839,     0.81825,      0.8181,     0.81796,     0.81782,     0.81767,     0.81753,     0.81739,     0.81724,      0.8171,     0.81695,     0.81681,     0.81667,     0.81652,     0.81638,     0.81624,     0.81609,     0.81595,      0.8158,     0.81566,     0.81552,\n",
       "            0.81537,     0.81523,      0.8144,     0.81351,     0.81262,     0.81173,     0.81084,     0.80994,     0.80905,     0.80816,     0.80727,     0.80638,     0.80549,      0.8046,     0.80301,     0.80115,     0.79929,     0.79744,     0.79558,     0.79372,     0.79302,     0.79249,     0.79196,\n",
       "            0.79143,      0.7909,     0.79036,     0.78983,      0.7893,     0.78877,     0.78824,     0.78771,     0.78718,     0.78665,     0.78612,     0.78559,     0.78506,     0.78453,       0.784,     0.78347,     0.78294,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,\n",
       "            0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,\n",
       "            0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,\n",
       "            0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,\n",
       "            0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,\n",
       "            0.78261,     0.78261,      0.7822,     0.78172,     0.78125,     0.78077,      0.7803,     0.77983,     0.77935,     0.77888,      0.7784,     0.77793,     0.77745,     0.77698,     0.77651,     0.77603,     0.77556,     0.77508,     0.77461,     0.77414,     0.77366,     0.77319,     0.77271,\n",
       "            0.77224,     0.77177,      0.7712,     0.77063,     0.77006,     0.76949,     0.76891,     0.76834,     0.76777,      0.7672,     0.76663,     0.76606,     0.76549,     0.76491,     0.76434,     0.76377,      0.7632,     0.76263,     0.76206,     0.76149,     0.76091,     0.75677,     0.75231,\n",
       "            0.74976,     0.74925,     0.74874,     0.74824,     0.74773,     0.74722,     0.74672,     0.74621,      0.7457,      0.7452,     0.74469,     0.74419,     0.74368,     0.74317,     0.74267,     0.74216,     0.74165,     0.74115,     0.74064,     0.74013,     0.73963,     0.73911,     0.73779,\n",
       "            0.73648,     0.73517,     0.73386,     0.73255,     0.73124,     0.72993,     0.72862,      0.7278,     0.72716,     0.72652,     0.72589,     0.72525,     0.72461,     0.72398,     0.72334,     0.72271,     0.72207,     0.72143,      0.7208,     0.72016,     0.71952,     0.71889,     0.71825,\n",
       "            0.71761,     0.71685,     0.71603,      0.7152,     0.71438,     0.71355,     0.71273,      0.7119,     0.71107,     0.71025,     0.70942,      0.7086,     0.70777,     0.70695,     0.70569,     0.70398,     0.70226,     0.70055,     0.69884,     0.69712,      0.6955,     0.69444,     0.69338,\n",
       "            0.69232,     0.69126,      0.6902,     0.68913,     0.68807,     0.68701,     0.68595,     0.68489,     0.68335,     0.68176,     0.68017,     0.67858,     0.67699,     0.67539,     0.67374,     0.67127,     0.66879,     0.66631,     0.66384,       0.658,     0.65057,     0.64314,     0.63572,\n",
       "            0.62882,     0.62325,     0.61806,      0.6136,     0.60915,     0.60469,     0.60023,     0.59783,     0.59241,     0.58692,     0.58506,      0.5832,     0.58135,     0.57949,     0.57763,     0.57422,     0.56479,     0.56256,     0.56033,      0.5581,     0.55588,     0.55085,     0.53971,\n",
       "            0.52991,     0.52249,     0.50904,     0.50458,     0.50012,     0.46746,     0.45628,     0.44555,     0.44332,     0.44109,     0.43886,     0.43664,     0.43353,     0.42611,     0.40781,      0.4011,     0.39664,     0.39219,     0.37746,     0.37374,     0.37003,     0.35219,     0.34323,\n",
       "            0.32723,     0.31552,      0.3116,     0.30789,     0.30383,     0.29308,     0.28751,     0.28128,      0.2711,     0.26664,     0.26218,     0.25301,     0.24729,     0.24358,     0.23986,     0.22379,     0.21822,     0.21468,      0.2115,     0.20831,     0.20165,      0.1936,     0.18914,\n",
       "             0.1847,     0.18099,     0.17727,     0.17178,     0.14092,     0.13774,     0.13456,     0.13137,     0.12519,     0.11849,     0.11403,     0.10957,     0.10571,       0.102,    0.098285,    0.095036,    0.091853,    0.088669,     0.08181,    0.064384,     0.06267,    0.060956,    0.059242,\n",
       "           0.057527,    0.055813,    0.054201,    0.053188,    0.052175,    0.051162,    0.050149,    0.049137,    0.048124,    0.047111,    0.046098,    0.045085,    0.044072,    0.034263,    0.022294,    0.020925,    0.020068,    0.019211,    0.018354,    0.017497,     0.01664,    0.015783,    0.014925,\n",
       "           0.014068,    0.013211,    0.012354,    0.011497,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.7143374065448143\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.71434])\n",
       "names: {0: 'tumor'}\n",
       "nt_per_class: array([92], dtype=int64)\n",
       "nt_per_image: array([82], dtype=int64)\n",
       "results_dict: {'metrics/precision(B)': 0.9482526070178302, 'metrics/recall(B)': 0.8260869565217391, 'metrics/mAP50(B)': 0.9259364565279764, 'metrics/mAP50-95(B)': 0.7143374065448143, 'fitness': 0.7143374065448143}\n",
       "save_dir: WindowsPath('C:/Users/LENOVO/runs/detect/train2')\n",
       "speed: {'preprocess': 0.28014756099298943, 'inference': 5.2120121951325356, 'loss': 0.00040975606768880405, 'postprocess': 2.3891536585080493}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # you can also use 'yolov8s.pt' for higher accuracy\n",
    "\n",
    "# Train\n",
    "model.train(\n",
    "    data=r\"D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\data.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0  # GPU\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae21050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.222  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\LENOVO\\runs\\detect\\train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 301.7144.3 MB/s, size: 61.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\labels\\train.cache... 325 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 325/325  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 43.928.8 MB/s, size: 56.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\labels\\val.cache... 82 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 82/82 24.0Kit/s 0.0s\n",
      "Plotting labels to C:\\Users\\LENOVO\\runs\\detect\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\LENOVO\\runs\\detect\\train3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      2.12G      1.337      3.328       1.54         14        640: 100% ━━━━━━━━━━━━ 21/21 1.4it/s 14.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.1it/s 1.0s0.7s\n",
      "                   all         82         92    0.00362      0.967      0.462      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      2.42G      1.179      1.978       1.34          8        640: 100% ━━━━━━━━━━━━ 21/21 3.6it/s 5.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.9it/s 1.0s0.8s\n",
      "                   all         82         92          1     0.0565      0.489      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      2.43G      1.254      1.949      1.408         14        640: 100% ━━━━━━━━━━━━ 21/21 3.5it/s 5.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.7it/s 1.1s0.8s\n",
      "                   all         82         92     0.0887      0.087     0.0476     0.0303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      2.45G      1.287      1.872      1.409          8        640: 100% ━━━━━━━━━━━━ 21/21 3.5it/s 6.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.3it/s 0.9s0.7s\n",
      "                   all         82         92      0.107     0.0543     0.0284     0.0135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      2.46G      1.305       1.79       1.41         19        640: 100% ━━━━━━━━━━━━ 21/21 4.3it/s 4.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.4it/s 0.9s0.7s\n",
      "                   all         82         92      0.442      0.353      0.348      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      2.47G       1.31      1.646      1.437         11        640: 100% ━━━━━━━━━━━━ 21/21 3.6it/s 5.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.9it/s 0.8s0.6s\n",
      "                   all         82         92      0.533       0.38      0.369      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      2.48G      1.266      1.511      1.391          6        640: 100% ━━━━━━━━━━━━ 21/21 4.4it/s 4.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.4it/s 0.9s0.6s\n",
      "                   all         82         92      0.415      0.348      0.286      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      2.48G      1.252      1.428      1.373          9        640: 100% ━━━━━━━━━━━━ 21/21 4.1it/s 5.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.8it/s 1.1s0.8s\n",
      "                   all         82         92       0.66      0.717       0.73      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      2.49G      1.245      1.383      1.406          5        640: 100% ━━━━━━━━━━━━ 21/21 3.1it/s 6.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.0it/s 1.0s0.8s\n",
      "                   all         82         92      0.784      0.631      0.739      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      2.49G      1.195      1.315      1.319          6        640: 100% ━━━━━━━━━━━━ 21/21 2.7it/s 7.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.8it/s 1.1s0.7s\n",
      "                   all         82         92      0.788      0.727       0.78      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      2.49G      1.198      1.262      1.343          6        640: 100% ━━━━━━━━━━━━ 21/21 4.1it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 0% ──────────── 0/3  0.0s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 43, in do_one_step\n    data = pin_memory(data, device)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 77, in pin_memory\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 77, in <dictcomp>\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 66, in pin_memory\n    return data.pin_memory(device)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train on your dataset\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mbain tumor\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mBrain Tumore image Dataset (1)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mbrain-tumor-dataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# train for 50 epochs\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# image size\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# adjust if GPU memory is low\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 0 means use GPU; use 'cpu' if no GPU\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\model.py:800\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m--> 800\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:240\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:475\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mval \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mpossible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_memory(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# prevent VRAM spike\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;66;03m# NaN recovery\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_nan_recovery(epoch):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:704\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema\u001b[38;5;241m.\u001b[39mema\u001b[38;5;241m.\u001b[39mbuffers():\n\u001b[0;32m    703\u001b[0m         dist\u001b[38;5;241m.\u001b[39mbroadcast(buffer, src\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 704\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\validator.py:206\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_metrics(unwrap_model(model))\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjdict \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# empty before each val\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_val_batch_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\utils\\tqdm.py:347\u001b[0m, in \u001b[0;36mTQDM.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoneType\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object is not iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\data\\build.py:77\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an iterator that yields indefinitely from the underlying iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1515\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1513\u001b[0m worker_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(idx)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1550\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data, worker_idx)\u001b[0m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1550\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils.py:750\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 43, in do_one_step\n    data = pin_memory(data, device)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 77, in pin_memory\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 77, in <dictcomp>\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 66, in pin_memory\n    return data.pin_memory(device)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Load YOLOv8 base model (you can change to yolov8s.pt for higher accuracy)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train on your dataset\n",
    "model.train(\n",
    "    data=r\"D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\data.yaml\",\n",
    "    epochs=50,      # train for 50 epochs\n",
    "    imgsz=640,      # image size\n",
    "    batch=16,       # adjust if GPU memory is low\n",
    "    device=0        # 0 means use GPU; use 'cpu' if no GPU\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e1a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.222  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "'data.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# or yolov8n.pt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate on your dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# use GPU only for eval\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\model.py:635\u001b[0m, in \u001b[0;36mModel.val\u001b[1;34m(self, validator, **kwargs)\u001b[0m\n\u001b[0;32m    632\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m    634\u001b[0m validator \u001b[38;5;241m=\u001b[39m (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator\u001b[39m\u001b[38;5;124m\"\u001b[39m))(args\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m--> 635\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validator\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\validator.py:178\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    175\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input of shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 3, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassify\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m check_cls_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msplit)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\data\\utils.py:406\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_det_dataset\u001b[39m(dataset: \u001b[38;5;28mstr\u001b[39m, autodownload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    392\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m    Download, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m        (dict[str, Any]): Parsed dataset information and paths.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n\u001b[0;32m    409\u001b[0m     extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\utils\\checks.py:592\u001b[0m, in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[0;32m    590\u001b[0m files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m file), recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m file))  \u001b[38;5;66;03m# find file\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple files match \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, specify exact path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: 'data.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO(\"yolo11n.pt\")  # or yolov8n.pt\n",
    "\n",
    "# Evaluate on your dataset\n",
    "metrics = model.val(data=\"data.yaml\", device='cuda:0')  # use GPU only for eval\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "354742e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.222  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 65.324.1 MB/s, size: 49.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\labels\\val.cache... 82 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 82/82 82.1Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.6it/s 9.6s0.5s\n",
      "                   all         82         92     0.0284        0.5     0.0396     0.0236\n",
      "                person         82         92     0.0284        0.5     0.0396     0.0236\n",
      "Speed: 10.5ms preprocess, 11.9ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\LENOVO\\runs\\detect\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(\n",
    "    data=r\"D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\data.yaml\",\n",
    "    device='cuda:0'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b469b57b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs\\\\detect\\\\train\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns/detect/train/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# your trained model path\u001b[39;00m\n\u001b[0;32m      5\u001b[0m results \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/your/image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# will open a window\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\models\\yolo\\model.py:83\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTDETR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\model.py:153\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\model.py:297\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    294\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights)\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtask\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:1517\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;124;03m    Load a single model weights.\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;124;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1517\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m   1519\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:1464\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight, safe_only)\u001b[0m\n\u001b[0;32m   1462\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch_load(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[0;32m   1463\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1464\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\utils\\patches.py:120\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs\\\\detect\\\\train\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")  # your trained model path\n",
    "results = model(\"path/to/your/image.jpg\", show=True)  # will open a window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800a6987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\104.jpg: 640x640 2 tumors, 8.9ms\n",
      "image 2/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\117.jpg: 640x640 (no detections), 14.8ms\n",
      "image 3/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\119.jpg: 640x640 1 tumor, 9.8ms\n",
      "image 4/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\128.jpg: 640x640 (no detections), 8.5ms\n",
      "image 5/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\131.jpg: 640x640 (no detections), 9.0ms\n",
      "image 6/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\132.jpg: 640x640 1 tumor, 16.2ms\n",
      "image 7/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\133.jpg: 640x640 1 tumor, 8.5ms\n",
      "image 8/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\138.jpg: 640x640 1 tumor, 9.5ms\n",
      "image 9/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\139.jpg: 640x640 (no detections), 15.0ms\n",
      "image 10/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\141.jpg: 640x640 1 tumor, 8.8ms\n",
      "image 11/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\15.jpg: 640x640 1 tumor, 10.9ms\n",
      "image 12/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\150.jpg: 640x640 1 tumor, 8.8ms\n",
      "image 13/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\151.jpg: 640x640 1 tumor, 8.9ms\n",
      "image 14/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\16.jpg: 640x640 1 tumor, 13.1ms\n",
      "image 15/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\160.jpg: 640x640 1 tumor, 26.3ms\n",
      "image 16/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\161.jpg: 640x640 2 tumors, 19.2ms\n",
      "image 17/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\164.jpg: 640x640 1 tumor, 11.9ms\n",
      "image 18/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\167.jpg: 640x640 1 tumor, 13.4ms\n",
      "image 19/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\168.jpg: 640x640 (no detections), 12.7ms\n",
      "image 20/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\17.jpg: 640x640 2 tumors, 41.7ms\n",
      "image 21/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\179.jpg: 640x640 1 tumor, 37.6ms\n",
      "image 22/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\180.jpg: 640x640 1 tumor, 40.2ms\n",
      "image 23/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\187.jpg: 640x640 1 tumor, 46.9ms\n",
      "image 24/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\189.jpg: 640x640 1 tumor, 50.1ms\n",
      "image 25/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\20.jpg: 640x640 (no detections), 47.6ms\n",
      "image 26/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\201.jpg: 640x640 1 tumor, 43.7ms\n",
      "image 27/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\204.jpg: 640x640 2 tumors, 40.0ms\n",
      "image 28/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\205.jpg: 640x640 (no detections), 38.3ms\n",
      "image 29/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\212.jpg: 640x640 (no detections), 73.9ms\n",
      "image 30/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\22.jpg: 640x640 1 tumor, 74.0ms\n",
      "image 31/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\223.jpg: 640x640 1 tumor, 34.8ms\n",
      "image 32/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\237.jpg: 640x640 1 tumor, 36.7ms\n",
      "image 33/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\238.jpg: 640x640 2 tumors, 35.1ms\n",
      "image 34/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\24.jpg: 640x640 (no detections), 34.7ms\n",
      "image 35/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\243.jpg: 640x640 1 tumor, 37.8ms\n",
      "image 36/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\248.jpg: 640x640 (no detections), 36.1ms\n",
      "image 37/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\256.jpg: 640x640 1 tumor, 88.6ms\n",
      "image 38/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\260.jpg: 640x640 1 tumor, 37.0ms\n",
      "image 39/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\266.jpg: 640x640 1 tumor, 31.9ms\n",
      "image 40/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\272.jpg: 640x640 1 tumor, 32.5ms\n",
      "image 41/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\275.jpg: 640x640 (no detections), 30.2ms\n",
      "image 42/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\276.jpg: 640x640 1 tumor, 38.2ms\n",
      "image 43/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\282.jpg: 640x640 (no detections), 82.1ms\n",
      "image 44/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\285.jpg: 640x640 (no detections), 34.4ms\n",
      "image 45/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\29.jpg: 640x640 1 tumor, 34.3ms\n",
      "image 46/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\290.jpg: 640x640 (no detections), 34.7ms\n",
      "image 47/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\292.jpg: 640x640 2 tumors, 35.8ms\n",
      "image 48/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\298.jpg: 640x640 1 tumor, 32.4ms\n",
      "image 49/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\3.jpg: 640x640 1 tumor, 38.6ms\n",
      "image 50/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\303.jpg: 640x640 (no detections), 36.3ms\n",
      "image 51/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\311.jpg: 640x640 1 tumor, 36.2ms\n",
      "image 52/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\312.jpg: 640x640 (no detections), 74.8ms\n",
      "image 53/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\315.jpg: 640x640 (no detections), 41.4ms\n",
      "image 54/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\325.jpg: 640x640 1 tumor, 36.8ms\n",
      "image 55/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\326.jpg: 640x640 (no detections), 36.7ms\n",
      "image 56/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\333.jpg: 640x640 1 tumor, 36.4ms\n",
      "image 57/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\338.jpg: 640x640 1 tumor, 35.4ms\n",
      "image 58/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\34.jpg: 640x640 1 tumor, 40.8ms\n",
      "image 59/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\348.jpg: 640x640 2 tumors, 88.4ms\n",
      "image 60/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\362.jpg: 640x640 1 tumor, 35.4ms\n",
      "image 61/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\369.jpg: 640x640 1 tumor, 36.2ms\n",
      "image 62/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\37.jpg: 640x640 1 tumor, 33.6ms\n",
      "image 63/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\374.jpg: 640x640 (no detections), 34.4ms\n",
      "image 64/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\375.jpg: 640x640 1 tumor, 34.6ms\n",
      "image 65/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\383.jpg: 640x640 2 tumors, 41.7ms\n",
      "image 66/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\387.jpg: 640x640 2 tumors, 40.4ms\n",
      "image 67/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\392.jpg: 640x640 1 tumor, 41.5ms\n",
      "image 68/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\393.jpg: 640x640 1 tumor, 35.1ms\n",
      "image 69/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\407.jpg: 640x640 (no detections), 83.5ms\n",
      "image 70/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\53.jpg: 640x640 1 tumor, 31.2ms\n",
      "image 71/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\61.jpg: 640x640 1 tumor, 31.4ms\n",
      "image 72/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\63.jpg: 640x640 (no detections), 44.7ms\n",
      "image 73/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\64.jpg: 640x640 (no detections), 31.6ms\n",
      "image 74/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\67.jpg: 640x640 1 tumor, 37.7ms\n",
      "image 75/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\7.jpg: 640x640 1 tumor, 36.2ms\n",
      "image 76/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\72.jpg: 640x640 1 tumor, 36.9ms\n",
      "image 77/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\80.jpg: 640x640 (no detections), 41.0ms\n",
      "image 78/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\81.jpg: 640x640 1 tumor, 36.7ms\n",
      "image 79/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\83.jpg: 640x640 1 tumor, 36.6ms\n",
      "image 80/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\93.jpg: 640x640 (no detections), 35.1ms\n",
      "image 81/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\96.jpg: 640x640 1 tumor, 36.9ms\n",
      "image 82/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\98.jpg: 640x640 1 tumor, 32.6ms\n",
      "Speed: 3.7ms preprocess, 35.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\LENOVO\\runs\\detect\\predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained YOLO model\n",
    "model = YOLO(r\"C:\\Users\\LENOVO\\runs\\detect\\train3\\weights\\best.pt\")\n",
    "\n",
    "# Run prediction on your validation images\n",
    "results = model.predict(\n",
    "    source=r\"D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\",  # your val folder\n",
    "    show=True,       # show images with bounding boxes\n",
    "    save=True,       # saves results (images with boxes) in runs/detect/predict\n",
    "    conf=0.5         # confidence threshold, adjust as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d724c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\104.jpg: 640x640 2 tumors, 16.8ms\n",
      "image 2/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\117.jpg: 640x640 (no detections), 34.8ms\n",
      "image 3/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\119.jpg: 640x640 1 tumor, 16.2ms\n",
      "image 4/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\128.jpg: 640x640 (no detections), 15.7ms\n",
      "image 5/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\131.jpg: 640x640 (no detections), 21.6ms\n",
      "image 6/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\132.jpg: 640x640 1 tumor, 14.2ms\n",
      "image 7/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\133.jpg: 640x640 1 tumor, 14.9ms\n",
      "image 8/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\138.jpg: 640x640 1 tumor, 12.8ms\n",
      "image 9/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\139.jpg: 640x640 (no detections), 19.4ms\n",
      "image 10/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\141.jpg: 640x640 1 tumor, 15.9ms\n",
      "image 11/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\15.jpg: 640x640 1 tumor, 17.6ms\n",
      "image 12/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\150.jpg: 640x640 1 tumor, 15.1ms\n",
      "image 13/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\151.jpg: 640x640 1 tumor, 14.9ms\n",
      "image 14/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\16.jpg: 640x640 1 tumor, 15.2ms\n",
      "image 15/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\160.jpg: 640x640 1 tumor, 17.7ms\n",
      "image 16/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\161.jpg: 640x640 2 tumors, 19.1ms\n",
      "image 17/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\164.jpg: 640x640 1 tumor, 14.8ms\n",
      "image 18/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\167.jpg: 640x640 1 tumor, 12.1ms\n",
      "image 19/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\168.jpg: 640x640 (no detections), 11.9ms\n",
      "image 20/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\17.jpg: 640x640 2 tumors, 16.0ms\n",
      "image 21/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\179.jpg: 640x640 1 tumor, 15.2ms\n",
      "image 22/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\180.jpg: 640x640 1 tumor, 16.2ms\n",
      "image 23/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\187.jpg: 640x640 1 tumor, 15.2ms\n",
      "image 24/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\189.jpg: 640x640 1 tumor, 14.6ms\n",
      "image 25/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\20.jpg: 640x640 (no detections), 20.3ms\n",
      "image 26/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\201.jpg: 640x640 1 tumor, 18.5ms\n",
      "image 27/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\204.jpg: 640x640 2 tumors, 19.2ms\n",
      "image 28/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\205.jpg: 640x640 (no detections), 15.2ms\n",
      "image 29/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\212.jpg: 640x640 (no detections), 12.1ms\n",
      "image 30/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\22.jpg: 640x640 1 tumor, 15.3ms\n",
      "image 31/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\223.jpg: 640x640 1 tumor, 13.7ms\n",
      "image 32/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\237.jpg: 640x640 1 tumor, 12.9ms\n",
      "image 33/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\238.jpg: 640x640 2 tumors, 11.9ms\n",
      "image 34/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\24.jpg: 640x640 (no detections), 14.5ms\n",
      "image 35/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\243.jpg: 640x640 1 tumor, 12.6ms\n",
      "image 36/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\248.jpg: 640x640 (no detections), 18.0ms\n",
      "image 37/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\256.jpg: 640x640 1 tumor, 12.9ms\n",
      "image 38/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\260.jpg: 640x640 1 tumor, 12.1ms\n",
      "image 39/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\266.jpg: 640x640 1 tumor, 12.4ms\n",
      "image 40/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\272.jpg: 640x640 1 tumor, 14.2ms\n",
      "image 41/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\275.jpg: 640x640 (no detections), 13.2ms\n",
      "image 42/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\276.jpg: 640x640 1 tumor, 15.1ms\n",
      "image 43/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\282.jpg: 640x640 (no detections), 14.0ms\n",
      "image 44/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\285.jpg: 640x640 (no detections), 18.3ms\n",
      "image 45/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\29.jpg: 640x640 1 tumor, 14.3ms\n",
      "image 46/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\290.jpg: 640x640 (no detections), 13.2ms\n",
      "image 47/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\292.jpg: 640x640 2 tumors, 15.6ms\n",
      "image 48/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\298.jpg: 640x640 1 tumor, 27.3ms\n",
      "image 49/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\3.jpg: 640x640 1 tumor, 19.4ms\n",
      "image 50/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\303.jpg: 640x640 (no detections), 16.2ms\n",
      "image 51/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\311.jpg: 640x640 1 tumor, 13.2ms\n",
      "image 52/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\312.jpg: 640x640 (no detections), 13.1ms\n",
      "image 53/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\315.jpg: 640x640 (no detections), 15.3ms\n",
      "image 54/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\325.jpg: 640x640 1 tumor, 13.5ms\n",
      "image 55/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\326.jpg: 640x640 (no detections), 21.2ms\n",
      "image 56/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\333.jpg: 640x640 1 tumor, 13.4ms\n",
      "image 57/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\338.jpg: 640x640 1 tumor, 15.8ms\n",
      "image 58/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\34.jpg: 640x640 1 tumor, 12.4ms\n",
      "image 59/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\348.jpg: 640x640 2 tumors, 14.0ms\n",
      "image 60/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\362.jpg: 640x640 1 tumor, 20.4ms\n",
      "image 61/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\369.jpg: 640x640 1 tumor, 11.9ms\n",
      "image 62/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\37.jpg: 640x640 1 tumor, 22.5ms\n",
      "image 63/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\374.jpg: 640x640 (no detections), 19.5ms\n",
      "image 64/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\375.jpg: 640x640 1 tumor, 24.2ms\n",
      "image 65/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\383.jpg: 640x640 2 tumors, 14.1ms\n",
      "image 66/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\387.jpg: 640x640 2 tumors, 22.2ms\n",
      "image 67/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\392.jpg: 640x640 1 tumor, 15.6ms\n",
      "image 68/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\393.jpg: 640x640 1 tumor, 16.3ms\n",
      "image 69/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\407.jpg: 640x640 (no detections), 12.9ms\n",
      "image 70/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\53.jpg: 640x640 1 tumor, 20.6ms\n",
      "image 71/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\61.jpg: 640x640 1 tumor, 16.4ms\n",
      "image 72/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\63.jpg: 640x640 (no detections), 13.0ms\n",
      "image 73/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\64.jpg: 640x640 (no detections), 14.5ms\n",
      "image 74/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\67.jpg: 640x640 1 tumor, 16.6ms\n",
      "image 75/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\7.jpg: 640x640 1 tumor, 15.0ms\n",
      "image 76/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\72.jpg: 640x640 1 tumor, 18.4ms\n",
      "image 77/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\80.jpg: 640x640 (no detections), 14.7ms\n",
      "image 78/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\81.jpg: 640x640 1 tumor, 14.6ms\n",
      "image 79/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\83.jpg: 640x640 1 tumor, 12.4ms\n",
      "image 80/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\93.jpg: 640x640 (no detections), 15.9ms\n",
      "image 81/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\96.jpg: 640x640 1 tumor, 12.3ms\n",
      "image 82/82 D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\\98.jpg: 640x640 1 tumor, 15.2ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load your trained YOLO model\n",
    "model = YOLO(r\"C:\\Users\\LENOVO\\runs\\detect\\train3\\weights\\best.pt\")\n",
    "\n",
    "# Run prediction on validation images (no saving)\n",
    "results = model.predict(\n",
    "    source=r\"D:\\bain tumor\\Brain Tumore image Dataset (1)\\brain-tumor-dataset\\images\\val\",\n",
    "    show=False,    # disable internal showing\n",
    "    save=False,    # don't save results\n",
    "    conf=0.5\n",
    ")\n",
    "\n",
    "# Display each image for 0.3 seconds (300 ms)\n",
    "for result in results:\n",
    "    img = result.plot()  # draw bounding boxes\n",
    "    window_name = \"Brain Tumor Detection\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(window_name, cv2.WND_PROP_TOPMOST, 1)\n",
    "    cv2.imshow(window_name, img)\n",
    "    \n",
    "    key = cv2.waitKey(300)  # show each image for 0.3 seconds\n",
    "    if key == 27:  # press ESC to stop early\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b030f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
